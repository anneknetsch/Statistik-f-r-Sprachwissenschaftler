Statistik für Sprachwissenschaftler
========================================================
author: Phillip M . Alday
date: 2014-05-26
autosize: false

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(cache=TRUE,prompt=TRUE)
library(knitcitations)
library(ggplot2)
library(reshape2)
cite_options(tooltip = TRUE
             , linked = TRUE
             , numerical = TRUE
             , bibtex_data = FALSE)
```

Aufwachen und sich errinnern!
====================================
type: section

Bisher
=======
- Konfidenz-Intervalle & frequentistische Inferenz
- Optional Stopping
- Credible Intervalle (HDI) & bayes'sche Inferenz, BEST

Heute
========
- Varianzanalyse
- F-Test 
- einfaktorielle ANOVA

Morgen
========
-

Datensätze für heute: Aphasiker und RT
==========================================
```{r, eval=FALSE}
aphasiker <- read.csv2("Data/aphasiker.csv",header = T)
aphasiker <- na.omit(aphasiker)
rt <- read.table("Data/punkt_rt.tab",header = T)
rt$subj <- as.factor(rt$subj)
```
```{r, echo=FALSE}
# the path in the previous block isn't correct, so run this one
aphasiker <- read.csv2(normalizePath("../Data/aphasiker.csv"),header = T)
aphasiker <- na.omit(aphasiker)
rt <- read.table(normalizePath("../Data/punkt_rt.tab"),header = T)
rt$subj <- as.factor(rt$subj)
```

Datensatz für heute: Aphasiker
================================
```{r, echo=FALSE}
qplot(x=Lex_Dec,geom="density",color=Aphasie,fill=Aphasie,data=aphasiker,alpha=I(0.3))
```

Datensatz für heute: RT
================================
```{r, echo=FALSE}
ggplot(data=rt) + geom_density(aes(x=RT,color=subj,fill=subj),alpha=0.5)
```


Varianzanalyse
=================
type: section


==================
was passiert, wenn wir mehr als zwei Gruppen vergleichen möchten?

Lösungsvorschlag I
===================
incremental: true

- paarweise Vergleiche
- Multiples Testen

Was macht der t-Test?
======================
incremental: true

$$ \frac{ \text{Beo} - \text{Theo} }{ s_\text{Beo}} $$

Ist der betrachtete Unterscheid größer als die Schwankungen, die durch Rauschen entstehen?

Ist der Abstand zwischen Gruppen größer als der Abstand zwischen Punkte innerhalb einer Gruppe?

Eine andere Perspektive
=========================
incremental: true
- Gruppe als unabhängige Variable
- Mittelwert als eine Funkion der Gruppe + Fehler

$$\text{Welt} = (\text{model}) + \text{Fehler}$$  

$$\text{Y} = F(X) + \epsilon{} $$  

$$\text{Y} = \beta{}X + \epsilon{} $$  

Eine andere Perspektive
=========================
```{r, echo=FALSE}
ggplot(rt, aes(x=subj,y=RT)) + geom_point() + geom_smooth(method="lm")
```

Eine andere Perspektive
=========================
```{r, echo=FALSE}
ggplot(subset(aphasiker, Aphasie %in% c("B","W"))) + geom_point(aes(x=Aphasie,y=Lex_Dec,color=Aphasie))
```

Eine andere Perspektive
=========================
```{r, echo=FALSE}
aphasiker$Aphasie <- factor(as.character(aphasiker$Aphasie), levels=c("C","A","B","W"))
ggplot(aphasiker) + geom_point(aes(x=Aphasie,y=Lex_Dec,color=Aphasie))
```

Eine andere Perspektive
=========================
incremental:true
- Ist die Auswirkung vom Model größer als die vom Fehler?
- Erklärt das Model oder der Fehler mehr Varianz?
- Erklären Intergruppen-Unterschiede mehr als Intragruppen-Unterschiede?

- Abhängige Variable: Reaktionszeit
- Unabhängige Variable: Gruppe
- zur Erinnerung: nominalskalierte unabhangige Variablen heißen auch Faktor, ihre Ausprägungen auch Faktorstufen


Lösungsvorschlag II
====================
incremental: true
- schauen, ob die gepoolte Intergruppen-Varianz größer als die gepoolte (durchschnittliche) Intragruppen-Varianz ist 
- $F$-Test !
- **AN**alysie **O**f **VA**riance

Einfaktorielle ANOVA
=====================
- beim Aphasiker-Datensatz untersuchen wir den Einfluss von nur einem Faktor, nämlich der Art der Aphasie
- denkbar wäre aber auch, dass der Einfluss eines weiterer Faktor, z.B. das Geschlecht der Versuchspersonen oder das der Modellperson mit berück-sichtigt wird -->  zwei-, bzw. dreifaktorielle ANOVA
- im Falle der dreifaktoriellen ANOVA (3x2x2) müssten wir also schon 12 Mittelwerte miteinander vergleichen!
- auch bei der ANOVA kann zwischen unabhängigen (ohne Messwiederholung) und abhängigen (mit Messwiederholung) Stichproben unterschieden werden

Grundidee der Varianzanalyse
==============================
- die einfache Varianzanalyse kann als eine Erweiterung des t-Tests für unabhängige Stichproben beschrieben werden 
- auch hier werden zwei Ursachen für Unterschiede zwischen Personen betrachtet: 
    - Unterschiede zwischen den Bedingungen 
    - Unterschiede innerhalb der Bedingungen
- wie die Bezeichnung Varianzanalyse bereits erahnen lässt, handelt es sich hier um ein Verfahren, bei dem die Variation in einer intervallskalierten Variable auf die Variation in einer/mehreren nominalskalierten Variablen/Faktoren zurückgeführt wird

Grundidee der Varianzanalyse
================================
- in welchem Maße ist die Gesamtvariation auf die unterschiedlichen Faktorstufen, also die experimentelle Manipulation zurückzuführen?
- Ist die Varianz innerhalb der Gruppen größer als die Varianz zwischen den Gruppen?
- wenn dies der Fall ist, dann spricht es dafür, dass die Unterschiede der Mittelwerte zufällig, d.h. durch die zufällige Zusammensetzung der Stichprobe zustande gekommen sind 
- statistische Hypothesen:
    - $H_0: \mu_1 = \mu_2 = \mu_3$ d.h. die Mittelwerte stammen aus Populationen mit gleichen Parametern
    - $H_1: \mu_i \neq \mu_j$ für mindestens ein Paar $(i,j), i \neq j$, d.h. mindestens zwei Mittelwerte unterscheiden sich

Daten
===========
```{r}
aggregate(Lex_Dec ~ Aphasie, data=aphasiker, FUN = mean)
```
***
```{r}
aggregate(Lex_Dec ~ Aphasie, data=aphasiker, FUN = var)
```

Welchen Größen werden zur Berechnung benötigt?
==================================================
<small>
Als Maß der Variation dient die Gesamtvarianz bzw. Gesamtquadratsumme $SS_\text{tot}$ (SS für engl. *sum of squares*):

- errechnet sich aus der Summe der quadrierten Abweichungen aller Messwerte vom Mittelwert, geteilt durch die Freiheitsgrade der Varianz ($n \times p - 1$), mit $n$ = Anzahl der Messwerte pro Gruppe, $p$ = Anzahl der Faktorstufen 
 
$$ \hat{\sigma}^2_\text{tot} = \frac{SS_\text{tot}}{df_\text{tot}} = \frac{\sum_i \sum_m \left(x_{m,i} - \bar{x} \right)^2}{np-1}$$
</small>


Welchen Größen werden zur Berechnung benötigt?
==================================================
<small>
$$ SS_\text{tot} = \sum_j \sum_m \left(x_{m,j} - \bar{x} \right)^2 $$

Allgemeines Scheme zur Schätzung der Varianzen: $$ \hat{\sigma}^2 = \frac{SS}{df} $$

</small>

Berechnung der Gesamtquadratsumme
===================================
```{r}
attach(aphasiker)
ss_tot <- sum( (Lex_Dec - mean(Lex_Dec))^2 )
ss_tot
```

Zerlegung der Gesamtquadratsumme
===================================
<small>
- die Gesamtqudratsumme $SS_\text{tot}$ wird in zwei Komponenten zerlegt: **Zwischen**-Quadratsumme und **Innerhalb**-Qudratsumme
- die Zwischen-Quadratsumme $SS_\text{zw}$  drückt die Variabilität zwischen den Bedingungen/Gruppen aus:
  - wird berechnet durch die Abweichungen der Gruppenmittelwerte vom Gesamtmittelwert
    $$ SS_\text{zw} = \sum_{j=1}^{p} \sum_{m=1}^{n_j} \left(\bar{x}_j - \bar{x} \right)^2 $$
- Varianz zwischen den Gruppen: MSSzw (mittlere Qudratsumme zwischen):
    $$ MSSzw = \frac{SS_\text{zw}}{p-1}$$   (mit $p$ = Anzahl an Faktorstufen)
</small>

Berechnung der Zwischen-Quadratsumme
========================================

Zerlegung der Gesamtquadratsumme
========================================
- die Innerhalb-Quadratsumme QSinn  drückt die Variabilität innerhalb den Bedingungen/Gruppen aus (wird auch als Fehlerquadratsumme bezeichnet):
    - wird berechnet durch die Abweichungen der einzelnen Werte einer Gruppe  vom Gruppenmittelwert:
      $$ SS_\text{inn} = \sum_{j=1}^{p} \sum_{m=1}^{n_j} \left(x_{mj} - \bar{x}_j \right)^2 $$
    - Varianz innerhalb den Gruppen: $MSS_\text{inn}$ (mittlere Quadratsumme innerhalb)
    $$ MSS_\text{inn} = \frac{SS_\text{inn}}{n-p} $$ mit $n$ = Stichprobenumfang, $p$ = Faktorstufen  

Berechnung der Innerhalb-Quadratsumme
========================================

Prüfgröße F
=============
<small>
- für den Signifikanztest benötigen wird die Prüfgröße $F$, deren Verteilung durch die Zählerfreiheitsgrade($p-1$) und Nennerfreiheitsgrade ($n-p$) beschrieben wird:

$$F = \frac{MSS_\text{zw}}{MSS_\text{inn}} $$

- Logik: Nullhypothese sagt, dass die Bedingungsmittelwerte in den $p$ verschiedenen Populationen gleich sind, dann schätzen beide MSS das gleiche: die zufällig zustande kommende Fehlervariation
- gilt jedoch die Alternativhypothese, dann wird der $F$-Wert umso größer, je größer die Varianz zwischen den Gruppen ist (--> Einfluss der systematischen Manipulation)
</small>

Prüfgröße F
=============
plot goes here

Prüfgröße F
=============
- die Prüfgröße stellt einen Quotienten aus zwei Quadratsummen dar, d.h. dass er nur positive Werte annehmen kann (im Falle der Nullhypothese näher er sich dem Wert 1 an)
- F-Werte können daher zwischen 0 und +unendlich variieren, wir können nur die rechte Seite, also nur einseitig testen
- Zusammenhang der Prüfgrößen F und t: für den Fall der einfaktoriellen ANOVA mit zwei Faktorstufen gilt: $F = t^2$

Berechnung der Prüfgröße F
===========================

- Schreibweise: F(Zähler,Nenner) = Wert, p=p-Wert

Berechnung in R mit aov
=======================
- Mit `aov()` werden die entsprechenden Quadratsummen berechnet
- Mit `summary()` kann man sich dann die $F$- und $p$-Werte anzeigen lassen


Logik der SS-Zerlegung
========================
- Die totale QS (Gesamtvarianz) wird zerlegt in zwei Bestandteile
- ist die QS-zwischen (erklärt durch unseren Faktor) ausreichend größer als die QS-innerhalb (Fehler), kann die Nullhypothese (kein Gruppenunterschied) zurückgewiesen werden

Pie Chart here

ANOVA und t-Test
====================
<small>
```{r}
t.test(Lex_Dec ~ Aphasie,data=subset(aphasiker,Aphasie %in% c("B","W")))
```
</small>

ANOVA und t-Test
====================
<small>
```{r}
summary(aov(Lex_Dec ~ Aphasie,data=subset(aphasiker,Aphasie %in% c("B","W"))))
```
</small>

Voraussetzungen
================
- Teilstichproben müssen unabhängig sein
- abhängige Variable muss mindestens intervallskaliert sein
- für Stichproben $n < 30$ muss die abhängige Variable in ihrer Population normalverteilt sein
- die Varianzen innerhalb aller Populationen müssen homogen sein, bei größeren Stichproben ist der Test auch bei Verletzung dieses Kriteriums robust

Interpretation der Ergebnisse
===============================
- wir haben in unserem Beispiel also einen $F$-Wert gefunden, der extremer ist als der entsprechende kritische $F$-Wert in der Verteilung
- dieser Wert sagt uns allerdings nur, dass sich mindestens zwei der drei Gruppen in ihren Mittelwerten signifikant unterscheiden, jedoch nicht, wie genau diese Unterschiede aussehen

Interpretation der Ergebnisse
==============================
- dazu werden post-hoc Tests durchgeführt, die gezielte Paarvergleiche anstellen
- hierbei ist jedoch das Problem der $\alpha$-Fehler-Kumulierung (oder -Inflation) zu berücksichtigen: je mehr Paarvergleiche (und damit Hypothesen) berechnet werden, desto größer ist die Chance die $H_0$ fälschlicherweise zu verwerfen
- es gibt hierfür entsprechende Korrekturen, die die post-hoc Tests "konservativer" machen

Mehrfaktorielle ANOVA
=======================
- wir haben uns nur den einfachsten Fall, eine einfaktorielle ANOVA ohne Messwiederholung, angeschaut
- wird in der Varianzanalyse der Einfluss von mehr als einem Faktor auf die abhängige Variable getestet, dann erhält man nicht nur **Haupteffekte** der einzelnen Faktoren, sondern auch **Interaktionen** zwischen den Faktoren
- würden wir in unserem Beispiel den Faktor "Geschlecht der Versuchsperson" hinzufügen, dann wäre es denkbar, dass wir unterschiedlichen Mittelwerte für das Nachahmungsverhalten in Abhängigkeit vom Geschlecht fänden

Hausaufgabe
===========


Bibliography
=============
```{r, echo=FALSE,results='hide'}
```
<span style="font-size: 10%;">
```{r,results='asis',echo=FALSE}
bibliography(style="markdown",bulleted=FALSE)
```
</span>